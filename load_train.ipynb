{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training/load_train.py\n",
    "import argparse\n",
    "\n",
    "def load_and_encode(state_dict):\n",
    "\n",
    "    from snowflake import snowpark as snp\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from collections import defaultdict\n",
    "    import pickle\n",
    "    \n",
    "    session = snp.Session.builder.configs(state_dict['connection_parameters']).create()\n",
    "    session.use_warehouse(state_dict['compute_parameters']['default_warehouse'])\n",
    "\n",
    "    feature_df = session.table(state_dict['feature_table_name']).to_pandas()\n",
    "    #forecast_df = session.table(state_dict['forecast_table_name']).to_pandas()\n",
    "\n",
    "    session.close()\n",
    "\n",
    "    feature_df['DATE'] = pd.to_datetime(feature_df['DATE'])\n",
    "    feature_df.set_index('DATE', inplace=True)\n",
    "    \n",
    "    #forecast_df['DATE'] = pd.to_datetime(forecast_df['DATE'])\n",
    "    #forecast_df.set_index('DATE', inplace=True)\n",
    "\n",
    "    cat_cols = state_dict['cat_cols']\n",
    "    num_cols = [set(feature_df.columns)-set(cat_cols)]\n",
    "    state_dict['num_cols'] = num_cols\n",
    "\n",
    "    try:\n",
    "        with open(state_dict['le_file_name'], 'rb') as fh: \n",
    "            d=pickle.load(fh)\n",
    "        feature_df[cat_cols]=feature_df[cat_cols].apply(lambda x: d[x.name].transform(x))\n",
    "\n",
    "    except: \n",
    "        d = defaultdict(LabelEncoder)\n",
    "        feature_df[cat_cols]=feature_df[cat_cols].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "        with open(state_dict['le_file_name'], 'wb') as fh: \n",
    "            pickle.dump(d, fh)\n",
    "\n",
    "    return state_dict, feature_df\n",
    "\n",
    "def train_and_save(state_dict, feature_df):\n",
    "    import pandas as pd\n",
    "    from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "    \n",
    "    feature_df.sort_values(by='DATE', ascending=True, inplace=True)\n",
    "\n",
    "    train_df = feature_df.groupby('STATION_ID').head(-365)\n",
    "    valid_df = feature_df.groupby('STATION_ID').tail(365)\n",
    "\n",
    "    state_dict['cat_idxs'] = [feature_df.drop(columns=['COUNT'], axis=1).columns.get_loc(col) for col in state_dict['cat_cols']]\n",
    "    state_dict['cat_dims'] = list(feature_df.drop(columns=['COUNT'], axis=1).iloc[:, state_dict['cat_idxs']].nunique().values)\n",
    "\n",
    "    y_train = train_df['COUNT'].values.reshape(-1,1)\n",
    "    X_train = train_df.drop(columns ='COUNT', axis=1).values\n",
    "\n",
    "    y_valid = valid_df['COUNT'].values.reshape(-1,1)\n",
    "    X_valid = valid_df.drop(columns ='COUNT', axis=1).values\n",
    "    \n",
    "    model = TabNetRegressor(cat_idxs=state_dict['cat_idxs'], cat_dims=state_dict['cat_dims'])\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        max_epochs=1,\n",
    "        patience=100,\n",
    "        batch_size=2048, \n",
    "        virtual_batch_size=256,\n",
    "        num_workers=0,\n",
    "        drop_last=True)\n",
    "\n",
    "    model.save_model(state_dict['model_file_name'].split('.')[0])\n",
    "    \n",
    "    return state_dict\n",
    "\n",
    "def pred(state_dict, feature_df):\n",
    "    from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "    import pandas as pd\n",
    "    from torch import tensor\n",
    "    \n",
    "    model = TabNetRegressor(cat_idxs=state_dict['cat_idxs'], cat_dims=state_dict['cat_dims'])\n",
    "\n",
    "    model.load_model(state_dict['model_file_name'])\n",
    "    \n",
    "    pred_df = feature_df.copy(deep=True)\n",
    "    \n",
    "    pred_df['PRED'] = model.predict(tensor(feature_df.drop(columns=['COUNT']).values)).round().astype('int')\n",
    "    \n",
    "    return state_dict, pred_df\n",
    "\n",
    "def forecast(state_dict, feature_df, forecast_df):\n",
    "\n",
    "    if len(state_dict['lag_values']) > 0:\n",
    "        for step in range(state_dict['forecast_steps']):\n",
    "            #station_id = df.iloc[-1]['STATION_ID']\n",
    "            future_date = df.iloc[-1]['DATE']+timedelta(days=1)\n",
    "            lags=[df.shift(lag-1).iloc[-1]['COUNT'] for lag in state_dict['lag_values']]\n",
    "            forecast=forecast_df.loc[forecast_df['DATE']==future_date.strftime('%Y-%m-%d')]\n",
    "            forecast=forecast.drop(labels='DATE', axis=1).values.tolist()[0]\n",
    "            features=[*lags, *forecast]\n",
    "            pred=round(model.predict(np.array([features]))[0][0])\n",
    "            row=[future_date, pred, *features, pred]\n",
    "            df.loc[len(df)]=row\n",
    "\n",
    "    return state_dict, pred_df\n",
    "\n",
    "def decode_and_write(state_dict, pred_df):\n",
    "    from snowflake import snowpark as snp\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    \n",
    "    with open(state_dict['le_file_name'], 'rb') as fh: \n",
    "        d=pickle.load(fh)\n",
    "\n",
    "    pred_df[state_dict['cat_cols']] = pred_df[state_dict['cat_cols']].apply(lambda x: d[x.name].inverse_transform(x))\n",
    "\n",
    "\n",
    "    session = snp.Session.builder.configs(state_dict['connection_parameters']).create()\n",
    "    session.use_warehouse(state_dict['compute_parameters']['default_warehouse'])\n",
    "\n",
    "    session.create_dataframe(pred_df).write.mode('overwrite').save_as_table(state_dict['pred_table_name'])\n",
    "    \n",
    "    session.close()\n",
    "    \n",
    "    return state_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Defining and parsing the command-line arguments\n",
    "    parser = argparse.ArgumentParser(description='airkube training')\n",
    "    parser.add_argument('--password', type=str)\n",
    "    parser.add_argument('--account', type=str)\n",
    "#     parser.add_argument('--username', type=str)\n",
    "#     parser.add_argument('--role', type=str)\n",
    "#     parser.add_argument('--database', type=str)\n",
    "#     parser.add_argument('--feature_table_name', type=str)\n",
    "#     parser.add_argument('--pred_table_name', type=str)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Creating the directory where the output file will be created (the directory may or may not exist).\n",
    "    #Path(args.accuracy).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    state_dict = {\"connection_parameters\": {\"password\": args.password},\n",
    "                  \"compute_parameters\" : {\"default_warehouse\": \"XSMALL_WH\"}}\n",
    "    state_dict['connection_parameters']['user'] = 'jack' #args.username\n",
    "    state_dict['connection_parameters']['account'] = args.account\n",
    "    state_dict['connection_parameters']['role']='PUBLIC'\n",
    "    state_dict['connection_parameters']['database']='CITIBIKEML_jack'\n",
    "    state_dict['connection_parameters']['schema']='DEMO'\n",
    "    state_dict['feature_table_name']='FEATURE_03A08400_EE3C_11EC_A5EE_ACDE48001122'\n",
    "    state_dict['pred_table_name']='PRED_03A08400_EE3C_11EC_A5EE_ACDE48001122'\n",
    "    state_dict['model_file_name']='forecast_model.zip'\n",
    "    state_dict['le_file_name']='label_encoders.pkl'\n",
    "    state_dict[\"cat_cols\"] = ['STATION_ID', 'HOLIDAY']\n",
    "\n",
    "    load_state_dict, feature_df = load_and_encode(state_dict)\n",
    "    train_state_dict = train_and_save(load_state_dict, feature_df)\n",
    "    pred_state_dict, pred_df = pred(state_dict, feature_df)\n",
    "    state_dict = decode_and_write(state_dict, pred_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_train import load_and_encode, train_and_save, pred, decode_and_write\n",
    "\n",
    "import getpass\n",
    "\n",
    "password = getpass.getpass('Enter password: ')\n",
    "state_dict = {\"connection_parameters\": {\"password\": password}, #args.password},\n",
    "              \"compute_parameters\" : {\"default_warehouse\": \"XSMALL_WH\"}\n",
    "             }\n",
    "state_dict['connection_parameters']['user'] = 'jack' #args.username\n",
    "state_dict['connection_parameters']['account'] = '' #args.account\n",
    "state_dict['connection_parameters']['role'] = 'PUBLIC'\n",
    "state_dict['connection_parameters']['database'] = 'CITIBIKEML_jack'\n",
    "state_dict['connection_parameters']['schema'] = 'DEMO'\n",
    "state_dict['feature_table_name'] = 'FEATURE_03A08400_EE3C_11EC_A5EE_ACDE48001122'\n",
    "state_dict['pred_table_name'] = 'PRED_03A08400_EE3C_11EC_A5EE_ACDE48001122'\n",
    "state_dict['model_file_name'] = 'forecast_model.zip'\n",
    "state_dict['le_file_name'] = 'label_encoders.pkl'\n",
    "state_dict[\"cat_cols\"] = ['STATION_ID', 'HOLIDAY']\n",
    "\n",
    "\n",
    "load_state_dict, feature_df = load_and_encode(state_dict)\n",
    "train_state_dict = train_and_save(load_state_dict, feature_df)\n",
    "pred_state_dict, pred_df = pred(state_dict, feature_df)\n",
    "state_dict = decode_and_write(state_dict, pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check output\n",
    "from snowflake import snowpark as snp\n",
    "\n",
    "session = snp.Session.builder.configs(state_dict['connection_parameters']).create()\n",
    "session.use_warehouse(state_dict['compute_parameters']['default_warehouse'])\n",
    "session.table(state_dict['pred_table_name']).show()\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec586a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
